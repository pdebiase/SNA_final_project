{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis - Final Project\n",
    "### Influence spread and virality II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- save outbreak simulation data to file\n",
    "- implement heap in CELF\n",
    "- implement CELF++\n",
    "- implement SA\n",
    "- implement multi-processing for outbreak simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import networkx as nx\n",
    "from functools import reduce\n",
    "import operator\n",
    "from random import choice\n",
    "import functools\n",
    "import os\n",
    "import heapq \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgelist_csv_to_graph(filename=\"./data/1jazz_edges.csv\"):\n",
    "    '''\n",
    "    Converts a .csv file in edgelist format to a networkX graph. \n",
    "    :param filename: relative path to the csv file\n",
    "    :return G: Returns a networkx undirected graph object\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(filename, sep=\";\")\n",
    "    G = nx.from_pandas_edgelist(df, source=\"Source\", target=\"Target\")\n",
    "    del df\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = edgelist_csv_to_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outbreak simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_outbreak(G, init_nodes=[], p=False, n_runs=10):\n",
    "    '''\n",
    "    Simulates an outbreak, either from a random node or a prespecified set of nodes.\n",
    "    :param G: networkx graph object to use as network\n",
    "    :param initial_infected nodes: list of nodes to start the outbreak from, if empty choose random node\n",
    "    :param n_runs: how many outbreaks to simulate\n",
    "    :return all_runs_list: returns a list of lists, where each \n",
    "                            inner list is a list of infected nodes resulting from that run\n",
    "    '''\n",
    "    \n",
    "    # List with all runs output\n",
    "    all_runs_list = []\n",
    "    # Run the algorithm 'n_runs' times\n",
    "    for run in range(n_runs):\n",
    "        np.random.seed(run)\n",
    "        initial_infected_nodes = []\n",
    "        # Using a fixed p or sampling from a 20-60 distribution\n",
    "        if p==False:\n",
    "            prob = np.random.uniform(20,60,1)[0]/100\n",
    "        else:\n",
    "            prob = p\n",
    "\n",
    "        if init_nodes==[]:\n",
    "            initial_infected_nodes = [choice(list(G.nodes()))]\n",
    "            \n",
    "        else:\n",
    "            initial_infected_nodes = init_nodes\n",
    "\n",
    "        # Random seed equals to run so we always can recover the same output\n",
    "        # np.random.seed(run)\n",
    "        # Nodes that are infecting other nodes in this time step\n",
    "        transmissible_nodes = initial_infected_nodes\n",
    "        # Nodes that become infected in this time step - at start, by default, none\n",
    "        just_infected = []\n",
    "        # History of all nodes that become infected - at the start just the the initial nodes\n",
    "        all_infected = [initial_infected_nodes]\n",
    "        # The algorithm runs when there is at least one trasmissible node\n",
    "        while transmissible_nodes:\n",
    "            # For each node recently infected we are going to check its neighbors and infect new nodes with probability p\n",
    "            for n in transmissible_nodes:\n",
    "                infection = np.random.uniform(0,1,len(list(G.neighbors(n)))) < prob\n",
    "                just_infected += list(np.extract(infection, list(G.neighbors(n))))\n",
    "            # Now the recent infected become the trasmissible nodes (only if they were not infected before)\n",
    "            transmissible_nodes = list(set(just_infected) - set(reduce(operator.concat, all_infected)))\n",
    "            # And they are added to the list with the history of all nodes infected\n",
    "            all_infected.extend([transmissible_nodes])\n",
    "        # Removing the last blank element (the last element is always a blank list)\n",
    "        all_infected = all_infected[:-1]\n",
    "        # Appending t the list with the output from all runs\n",
    "        all_runs_list.append(all_infected)\n",
    "\n",
    "    return all_runs_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fraction of information cascades and contamination events detected by the selected nodes\n",
    "def detection_likelihood(outbreak_simulations, placement, inverse=True):\n",
    "    '''\n",
    "    For a given run or multiple runs, calculate the placement score with detection likelihood as objective\n",
    "    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak\n",
    "    :param placement: solution set of nodes to calculate score for\n",
    "    :param inverse: if inverse is set to True, return 1 - detection likelihood score, such that a lower score is a better score\n",
    "    :return: Returns the average detection likelihood score (between 0 and 1) over all runs\n",
    "    '''\n",
    "    detection_count = 0\n",
    "    # For each run we need to compute the detection likelihood\n",
    "    for run in outbreak_simulations:\n",
    "        # If any node in the placement got infeceted then we detected the outbreak\n",
    "        if list(set(placement) & set(reduce(operator.concat, run))):\n",
    "            detection_count += 1\n",
    "    # We need the detection likelihood thus the number of detection divded by the total number of simulations\n",
    "    dl = (detection_count/len(outbreak_simulations))\n",
    "    if inverse:\n",
    "        return 1-dl\n",
    "    \n",
    "    else:\n",
    "          return dl\n",
    "\n",
    "def detection_time(outbreak_simulations, placement):\n",
    "    '''\n",
    "    For a given run or multiple runs, calculate the placement score with detection time as objective\n",
    "    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak\n",
    "    :param placement: solution set of nodes to calculate score for\n",
    "    :return: Returns the average detection time score over all runs\n",
    "    '''\n",
    "          \n",
    "    # Output is a list with the time step in which the outbreak was detected for each run\n",
    "    output = []\n",
    "    # Creating a set for the placement\n",
    "    set_placement = set(placement)\n",
    "    # For each run we need to compute the detection time\n",
    "    for run in outbreak_simulations:\n",
    "        # If any node in the placement got infeceted then we detected the outbreak and we need to check the detection time\n",
    "        intersection = list(set_placement & set(reduce(operator.concat, run)))\n",
    "        if intersection:\n",
    "            # For each step and nodes infected in this step we are going to check if the placement detected it\n",
    "            for step,nodes in enumerate(run):\n",
    "                # If any element in the intersection is in this set of nodes, than it was detected at this time step\n",
    "                if list(set(intersection) & set(nodes)):\n",
    "                    output.append(step)\n",
    "                    break\n",
    "        # If not detected, than the detection time is the max penalty\n",
    "        else:\n",
    "            max_penalty = len(run)\n",
    "            output.append(max_penalty)\n",
    "    return np.mean(output)\n",
    "\n",
    "def population_affected(outbreak_simulations, placement):\n",
    "    '''\n",
    "    For a given run or multiple runs, calculate the placement score with population affected as objective\n",
    "    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak\n",
    "    :param placement: solution set of nodes to calculate score for\n",
    "    :return: Returns the average population affected score over all runs\n",
    "    '''\n",
    "          \n",
    "    # Output is a list with the population affected in each outbreak run\n",
    "    output = []\n",
    "    # Creating a set for the placement\n",
    "    set_placement = set(placement)\n",
    "    # For each run we need to compute the population affected\n",
    "    for run in outbreak_simulations:\n",
    "        pa = 0\n",
    "        # If any node in the placement got infeceted then we detected the outbreak and we need to check the population affected\n",
    "        intersection = list(set_placement & set(reduce(operator.concat, run)))\n",
    "        if intersection:\n",
    "            # For each step and nodes infected in this step we are going to check if the placement detected it\n",
    "            for nodes in run:\n",
    "                # If any element in the intersection is in this set of nodes, then it was detected at this time step\n",
    "                # and we can finish by appending the population affected to the output and breaking the run\n",
    "                if list(set(intersection) & set(nodes)):\n",
    "                    output.append(pa)\n",
    "                    break\n",
    "                else:\n",
    "                # If not, then we need to sum the non-detected nodes to the pop affected\n",
    "                    pa += len(nodes)\n",
    "        # If not detected, than the pop affected is the size of the outbreak\n",
    "        else:\n",
    "            output.append(len(reduce(operator.concat, run)))\n",
    "    return np.mean(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive greedy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_greedy(outbreak_simulations, budget, eval_function, G, verbosity=2):\n",
    "    '''\n",
    "    Using a naive greedy strategy: find the best placement, given outbreak simulation data and an objective function, constrained to a budget.\n",
    "    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak\n",
    "    :param budget: The total cost of selecting nodes cannot exceed the budget\n",
    "    :param eval_function: Which objective function to use to calculate placement score\n",
    "    :param G: networkx graph object to use as network\n",
    "    :return placement: Return best found solution set of nodes\n",
    "    \n",
    "    '''\n",
    "    t_total = time.time()\n",
    "    eval_function = functools.partial(eval_function, outbreak_simulations=outbreak_simulations)\n",
    "    nodes = list(G.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    placement = []\n",
    "#     total_gain = 0\n",
    "    #Finding best placement\n",
    "    for i in range(budget):\n",
    "        t_iter = time.time()\n",
    "        scores = []\n",
    "        for n in nodes:\n",
    "            placement.append(n)\n",
    "            scores.append(eval_function(placement=placement))\n",
    "            placement.remove(n)\n",
    "        best_node = nodes[np.argmin(scores)]\n",
    "        placement.append(best_node)\n",
    "        nodes.remove(best_node)\n",
    "        \n",
    "        if verbosity >= 2:\n",
    "            print(\"Finished iteration \" + str(i+1) + \" in \" + str(time.time()-t_iter))\n",
    "        \n",
    "    if verbosity >= 1:\n",
    "        print(\"Total time: \" + str(time.time()-t_total))\n",
    "    \n",
    "    return placement, eval_function(placement=placement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CELF\n",
    "\n",
    "1. Maintain priority queue (u, u.marginal_gain, u.iter)\n",
    "2. If node chosen had its marginal_gain computer in the current iteration, then it must be the best node for the current iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handy link to understand min heap implementation: https://www.techbeamers.com/python-heapq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELF(outbreak_simulations, budget, eval_function, G, verbosity = 2):\n",
    "    '''\n",
    "    Using the CELF algorithm: find the best placement, given outbreak simulation data and an objective function, constrained to a budget.\n",
    "    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak\n",
    "    :param budget: The total cost of selecting nodes cannot exceed the budget\n",
    "    :param eval_function: Which objective function to use to calculate placement score\n",
    "    :param G: networkx graph object to use as network\n",
    "    :return placement: Return best found solution set of nodes\n",
    "    '''\n",
    "  \n",
    "    t_total = time.time()\n",
    "\n",
    "    eval_function = functools.partial(eval_function, outbreak_simulations=outbreak_simulations)\n",
    "\n",
    "    nodes = list(G.nodes())\n",
    "\n",
    "    # Construct heap for first iteration of format (marginal gain, node)\n",
    "    node_heap = []\n",
    "    placement = []\n",
    "    scores = []\n",
    "    total_penalty = eval_function(placement = [])\n",
    "    t_iter = time.time()\n",
    "    for node in nodes:\n",
    "        penalty = eval_function(placement = [node])\n",
    "        marginal_gain = total_penalty - penalty\n",
    "        # heapq implements a min heap, which keeps the smallest element at the top of the heap\n",
    "        # but we need it the other way around, therefore we multiply the marginal_gain by -1\n",
    "        heapq.heappush(node_heap, (-marginal_gain, node))\n",
    "    \n",
    "    # Remove best node from heap and add to solution set\n",
    "    best_gain, best_node = heapq.heappop(node_heap)\n",
    "    total_penalty = total_penalty -\n",
    "    placement.append(best_node)\n",
    "    \n",
    "    if verbosity >= 2:\n",
    "        print(\"Finished iteration \" + str(len(placement)) + \" in \" + str(time.time()-t_iter))\n",
    "\n",
    "    \n",
    "    while len(placement) < budget:\n",
    "        t_iter = time.time()\n",
    "#         Recompute gain only for top node\n",
    "\n",
    "#         Sort by gain\n",
    "\n",
    "#         If a is still top node:\n",
    "#         Add to solution\n",
    "#         Else:\n",
    "#         Recompute gain for new top node\n",
    "        top_node_unchanged = False\n",
    "\n",
    "        while not top_node_unchanged:\n",
    "            _, current_node = heapq.heappop(node_heap)\n",
    "            placement.append(current_node)\n",
    "            current_penalty = eval_function(placement=placement)\n",
    "            placement.remove(current_node)\n",
    "            marginal_gain = total_penalty - current_penalty\n",
    "\n",
    "            # check if the previous top node stayed on the top after pushing\n",
    "            # the marginal gain to the heap\n",
    "            heapq.heappush(node_heap, (-marginal_gain, current_node))\n",
    "            _, top_node = node_heap[0]\n",
    "            \n",
    "            if top_node == current_node:\n",
    "                top_node_unchanged = True\n",
    "            \n",
    "        marginal_gain, current_node = heapq.heappop(node_heap)\n",
    "        # marginal gain is stored as negative, so use plus instead of minus\n",
    "        total_penalty = total_penalty + marginal_gain\n",
    "        \n",
    "        placement.append(current_node)\n",
    "        \n",
    "        if verbosity >= 2:\n",
    "            print(\"Finished iteration \" + str(len(placement)) + \" in \" + str(time.time()-t_iter))\n",
    "            print(eval_function(placement = placement))\n",
    "    \n",
    "    if verbosity >= 1:\n",
    "        print(\"Total time: \" + str(time.time()-t_total))\n",
    "               \n",
    "    return placement, eval_function(placement = placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE\n",
      "Finished iteration 1 in 2.6556804180145264\n",
      "Finished iteration 2 in 2.265080690383911\n",
      "Finished iteration 3 in 2.1713662147521973\n",
      "Finished iteration 4 in 2.155748128890991\n",
      "Finished iteration 5 in 2.233853340148926\n",
      "Total time: 11.481728792190552\n",
      "[67, 7, 31, 20, 32]\n",
      "1.448\n",
      "CELF\n",
      "Finished iteration 1 in 2.8431172370910645\n",
      "Finished iteration 2 in 2.279677629470825\n",
      "1.733\n",
      "Finished iteration 3 in 0.015622854232788086\n",
      "1.629\n",
      "Finished iteration 4 in 0.01565098762512207\n",
      "1.561\n",
      "Finished iteration 5 in 0.015624523162841797\n",
      "1.517\n",
      "Total time: 5.216492176055908\n",
      "[67, 7, 23, 20, 133]\n",
      "1.517\n"
     ]
    }
   ],
   "source": [
    "# Generating outbreaks scenarios and other parameters\n",
    "n_scenarios = 1000\n",
    "outbreak_simulations = simulate_outbreak(G=G, n_runs=n_scenarios)\n",
    "budget = 5\n",
    "\n",
    "# Naive Algorithm\n",
    "print(\"NAIVE\")\n",
    "naive_placement, naive_score = naive_greedy(outbreak_simulations, budget=budget, eval_function = detection_time, G=G)\n",
    "print(naive_placement)\n",
    "print(naive_score)\n",
    "# CELF\n",
    "print(\"CELF\")\n",
    "i_time = time.time()\n",
    "celf_placement, celf_score = CELF(outbreak_simulations, budget=budget, eval_function = detection_time, G=G)\n",
    "print(celf_placement)\n",
    "print(celf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.45"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_affected(outbreak_simulations, [20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
