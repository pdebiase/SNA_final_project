# -*- coding: utf-8 -*-
"""
Created on Sun Nov 24 19:07:31 2019

@author: pvbia
"""

import numpy as np
import pandas as pd
import time
import networkx as nx
import functools
import heapq 
import pickle
from multiprocessing import Pool
import EvaluationFunctions as ef



#####################################  DATA PREPARATION ########################################################################## 

def edgelist_csv_to_graph(filename="./data/1jazz_edges.csv"):
    '''
    Converts a .csv file in edgelist format to a networkX graph. 
    :param filename: relative path to the csv file
    :return G: Returns a networkx undirected graph object
    '''

    df = pd.read_csv(filename, sep=";")
    G = nx.from_pandas_edgelist(df, source="Source", target="Target")
    del df
    return G

####################################### EVALUATION FUNCTIONS ###################################################################

#Fraction of information cascades and contamination events detected by the selected nodes
def detection_likelihood_mean(outbreak_simulations, placement, inverse=True):
    '''
    For a given run or multiple runs, calculate the placement score with detection likelihood as objective
    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak
    :param placement: solution set of nodes to calculate score for
    :param inverse: if inverse is set to True, return 1 - detection likelihood score, such that a lower score is a better score
    :return: Returns the average detection likelihood score (between 0 and 1) over all runs
    '''
    function = functools.partial(ef.detection_likelihood,placement=placement)
    if __name__ == '__main__':
        pool = Pool(6)
        results = pool.map(function, outbreak_simulations)
    return np.mean(results)

def detection_time_mean(outbreak_simulations, placement):
    '''
    For a given run or multiple runs, calculate the placement score with detection time as objective
    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak
    :param placement: solution set of nodes to calculate score for
    :return: Returns the average detection time score over all runs
    '''
    function = functools.partial(ef.detection_time,placement=placement)
    if __name__ == '__main__':
        pool = Pool(6)
        results = pool.map(function, outbreak_simulations)
    return np.mean(results)

def population_affected_mean(outbreak_simulations, placement):
    '''
    For a given run or multiple runs, calculate the placement score with population affected as objective
    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak
    :param placement: solution set of nodes to calculate score for
    :return: Returns the average population affected score over all runs
    '''
    function = functools.partial(ef.population_affected,placement=placement)
    if __name__ == '__main__':
        pool = Pool(6)
        results = pool.map(function, outbreak_simulations)
    return np.mean(results)

####################################### ALGORITHMS ###################################################################

def naive_greedy(outbreak_simulations, budget, eval_function, G, verbosity=2):
    '''
    Using a naive greedy strategy: find the best placement, given outbreak simulation data and an objective function, constrained to a budget.
    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak
    :param budget: The total cost of selecting nodes cannot exceed the budget
    :param eval_function: Which objective function to use to calculate placement score
    :param G: networkx graph object to use as network
    :return placement: Return best found solution set of nodes
    
    '''
    t_total = time.time()
    eval_function = functools.partial(eval_function, outbreak_simulations=outbreak_simulations)
    nodes = list(G.nodes())
    placement = []
#     total_gain = 0
    #Finding best placement
    for i in range(budget):
        t_iter = time.time()
        scores = []
        for n in nodes:
            placement.append(n)
            scores.append(eval_function(placement=placement))
            placement.remove(n)
        best_node = nodes[np.argmin(scores)]
        placement.append(best_node)
        nodes.remove(best_node)
        
        if verbosity >= 2:
            print("Finished iteration " + str(i+1) + " in " + str(time.time()-t_iter))
        
    if verbosity >= 1:
        print("Total time: " + str(time.time()-t_total))
    
    return placement, eval_function(placement=placement)


def CELF(outbreak_simulations, budget, eval_function, G, verbosity = 2):
    '''
    Using the CELF algorithm: find the best placement, given outbreak simulation data and an objective function, constrained to a budget.
    :param outbreak_simulations: outbreak simulation data generated by simulate_outbreak
    :param budget: The total cost of selecting nodes cannot exceed the budget
    :param eval_function: Which objective function to use to calculate placement score
    :param G: networkx graph object to use as network
    :return placement: Return best found solution set of nodes
    '''
  
    t_total = time.time()
    fe_total = 0
    eval_function = functools.partial(eval_function, outbreak_simulations=outbreak_simulations)

    nodes = list(G.nodes())

    # Construct heap for first iteration of format (marginal gain, node)
    node_heap = []
    placement = []
    total_penalty = eval_function(placement = [])
    fe_total += 1
    t_iter = time.time()
    for node in nodes:
        penalty = eval_function(placement = [node])
        fe_total += 1
        marginal_gain = total_penalty - penalty
        # heapq implements a min heap, which keeps the smallest element at the top of the heap
        # but we need it the other way around, therefore we multiply the marginal_gain by -1
        heapq.heappush(node_heap, (-marginal_gain, node))
    
    # Remove best node from heap and add to solution set
    best_gain, best_node = heapq.heappop(node_heap)
    total_penalty = total_penalty + best_gain
    placement.append(best_node)
    
    if verbosity >= 2:
        print("Finished iteration " + str(len(placement)) + " in " + str(time.time()-t_iter))

    
    while len(placement) < budget:
        t_iter = time.time()
        top_node_unchanged = False

        while not top_node_unchanged:
            _, current_node = heapq.heappop(node_heap)
            placement.append(current_node)
            current_penalty = eval_function(placement=placement)
            fe_total += 1
            placement.remove(current_node)
            marginal_gain = total_penalty - current_penalty

            # check if the previous top node stayed on the top after pushing
            # the marginal gain to the heap
            heapq.heappush(node_heap, (-marginal_gain, current_node))
            _, top_node = node_heap[0]
            
            if top_node == current_node:
                top_node_unchanged = True
            
        marginal_gain, current_node = heapq.heappop(node_heap)
        # marginal gain is stored as negative, so use plus instead of minus
        total_penalty = total_penalty + marginal_gain
        
        placement.append(current_node)
        
        if verbosity >= 2:
            print("Finished iteration " + str(len(placement)) + " in " + str(time.time()-t_iter))
            print(eval_function(placement = placement))
    
    if verbosity >= 1:
        print("Total time: " + str(time.time()-t_total))
        print("Total function evaluations: " + str(fe_total))

    return placement, eval_function(placement = placement)


####################################### EXPERIMENTS ###################################################################
    
file_names = [["1jazz_outbreaks.data", "./data/1jazz_edges.csv","1jazz"],
              ["2tvshow_outbreaks.data","./data/2tvshow_edges.csv","2tvshow"],
              ["3politician_outbreaks.data","./data/33politician_edges.csv","3politician"],
              ["4public_figure_outbreaks.data","./data/4public_figure_edges.csv","4public_figure"],
              ["5new_sites_outbreaks.data","./data/5new_sites_edges.csv","5news_sites"]
             ]

budgets = [1,5,10,15,20]

functions = [detection_likelihood_mean,detection_time_mean,population_affected_mean]

algorithms = [naive_greedy,CELF]

df = pd.DataFrame(columns=['Algorithm','Budget','Dataset','Runtime','Criterion','Score'])

index = 0
for file in file_names:
    with open(file, 'rb') as filehandle:
        # read the data as binary data stream
        data = pickle.load(filehandle)
    G = edgelist_csv_to_graph(file[1])
    for a in algorithms:
        for b in budgets:
            for eval_function in functions:
                    #running
                    start = time.time()
                    [placement, score] = a(data, b, eval_function, G, verbosity=2)
                    df.loc[index] = [a.__name__,b,file[2],time.time()-start,eval_function.__name__,score]
                    index += 1
                    
df.to_csv("performance_df.csv")